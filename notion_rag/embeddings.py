"""
Embedding generation for the Notion RAG system.
Uses HuggingFace sentence-transformers for generating embeddings.
"""

import os
from typing import List, Optional, Dict, Any
from pathlib import Path
import logging
from functools import lru_cache

try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False
    SentenceTransformer = None

from .config import Config
from .security import InputValidator

logger = logging.getLogger(__name__)


class EmbeddingGenerator:
    """Base class for embedding generators."""
    
    def __init__(self, config: Config):
        """
        Initialize the embedding generator.
        
        Args:
            config: Configuration object
        """
        self.config = config
        self.model_name = "BAAI/bge-small-en-v1.5"
        self.embedding_dimension = 384  # bge-small-en-v1.5 dimension
    
    def generate_embeddings(self, texts: List[str], batch_size: int = 32) -> List[List[float]]:
        """
        Generate embeddings for a list of texts.
        
        Args:
            texts: List of text strings to embed
            batch_size: Number of texts to process in each batch
            
        Returns:
            List of embedding vectors (each vector is a list of floats)
        """
        raise NotImplementedError("Subclasses must implement generate_embeddings")
    
    def generate_single_embedding(self, text: str) -> List[float]:
        """
        Generate embedding for a single text.
        
        Args:
            text: Text string to embed
            
        Returns:
            Embedding vector as a list of floats
        """
        embeddings = self.generate_embeddings([text])
        return embeddings[0] if embeddings else []
    
    def get_embedding_dimension(self) -> int:
        """Get the dimension of embeddings generated by this model."""
        return self.embedding_dimension


class HuggingFaceEmbeddingGenerator(EmbeddingGenerator):
    """HuggingFace sentence-transformers based embedding generator."""
    
    def __init__(self, config: Config, model_name: Optional[str] = None):
        """
        Initialize the HuggingFace embedding generator.
        
        Args:
            config: Configuration object
            model_name: Optional model name to override default
        """
        super().__init__(config)
        
        if model_name:
            self.model_name = model_name
        
        if not SENTENCE_TRANSFORMERS_AVAILABLE:
            raise ImportError(
                "sentence-transformers is not installed. "
                "Install it with: pip install sentence-transformers"
            )
        
        self.model = self._load_model()
        logger.info(f"Initialized HuggingFace embedding generator with model: {self.model_name}")
    
    @lru_cache(maxsize=1)
    def _load_model(self) -> Any:
        """
        Load the sentence transformer model.
        Uses LRU cache to avoid reloading the model.
        
        Returns:
            Loaded SentenceTransformer model
        """
        try:
            logger.info(f"Loading sentence transformer model: {self.model_name}")
            model = SentenceTransformer(self.model_name)
            
            # Update embedding dimension based on actual model
            self.embedding_dimension = model.get_sentence_embedding_dimension()
            logger.info(f"Model loaded successfully. Embedding dimension: {self.embedding_dimension}")
            
            return model
        except Exception as e:
            logger.error(f"Failed to load model {self.model_name}: {str(e)}")
            raise
    
    def generate_embeddings(self, texts: List[str], batch_size: int = 32) -> List[List[float]]:
        """
        Generate embeddings for a list of texts using sentence-transformers.
        
        Args:
            texts: List of text strings to embed
            batch_size: Number of texts to process in each batch
            
        Returns:
            List of embedding vectors (each vector is a list of floats)
        """
        if not texts:
            return []
        
        try:
            # Sanitize and validate inputs
            sanitized_texts = []
            for text in texts:
                sanitized_text = InputValidator.sanitize_text(text, max_length=8192)  # Reasonable limit for embeddings
                if sanitized_text.strip():
                    sanitized_texts.append(sanitized_text)
            
            if not sanitized_texts:
                logger.warning("No valid texts provided for embedding generation")
                return []
            
            logger.info(f"Generating embeddings for {len(sanitized_texts)} texts with batch size {batch_size}")
            
            # Generate embeddings in batches
            all_embeddings = []
            for i in range(0, len(sanitized_texts), batch_size):
                batch_texts = sanitized_texts[i:i + batch_size]
                
                # Generate embeddings for this batch
                batch_embeddings = self.model.encode(
                    batch_texts,
                    convert_to_tensor=False,  # Return as numpy arrays
                    show_progress_bar=False,
                    normalize_embeddings=True  # Normalize for better similarity search
                )
                
                # Convert to list of lists
                batch_embeddings_list = batch_embeddings.tolist()
                all_embeddings.extend(batch_embeddings_list)
                
                logger.debug(f"Processed batch {i//batch_size + 1}, generated {len(batch_embeddings_list)} embeddings")
            
            logger.info(f"Successfully generated {len(all_embeddings)} embeddings")
            return all_embeddings
            
        except Exception as e:
            logger.error(f"Failed to generate embeddings: {str(e)}")
            raise
    
    def generate_single_embedding(self, text: str) -> List[float]:
        """
        Generate embedding for a single text.
        
        Args:
            text: Text string to embed
            
        Returns:
            Embedding vector as a list of floats
        """
        embeddings = self.generate_embeddings([text])
        return embeddings[0] if embeddings else []
    
    def get_model_info(self) -> Dict[str, Any]:
        """
        Get information about the loaded model.
        
        Returns:
            Dictionary with model information
        """
        return {
            "model_name": self.model_name,
            "embedding_dimension": self.embedding_dimension,
            "max_sequence_length": getattr(self.model, 'max_seq_length', 'unknown'),
            "model_type": "sentence-transformers"
        }


def create_embedding_generator(config: Config, model_name: Optional[str] = None) -> EmbeddingGenerator:
    """
    Factory function to create an embedding generator.
    
    Args:
        config: Configuration object
        model_name: Optional model name to use
        
    Returns:
        Configured embedding generator
    """
    if not SENTENCE_TRANSFORMERS_AVAILABLE:
        raise ImportError(
            "sentence-transformers is not installed. "
            "Install it with: pip install sentence-transformers"
        )
    
    return HuggingFaceEmbeddingGenerator(config, model_name)


# Convenience function for quick embedding generation
def generate_embeddings(texts: List[str], config: Config, model_name: Optional[str] = None) -> List[List[float]]:
    """
    Convenience function to generate embeddings for a list of texts.
    
    Args:
        texts: List of text strings to embed
        config: Configuration object
        model_name: Optional model name to use
        
    Returns:
        List of embedding vectors
    """
    generator = create_embedding_generator(config, model_name)
    return generator.generate_embeddings(texts) 